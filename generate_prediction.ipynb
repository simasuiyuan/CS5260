{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traceback import print_tb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as data\n",
    "import torch\n",
    "import json\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "tqdm.pandas()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "%matplotlib inline\n",
    "# IMAGE_PATH = Path(\"/etlstage/PEE_joint/mine/image_data\")\n",
    "# %%\n",
    "nltk.data.path.append(\"/home/hdfsf10n/nltk_data\")\n",
    "nltk.data.path\n",
    "# %%\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from src.utils.data_loader import get_loader\n",
    "# %%\n",
    "with open('./data/vaild_dataset.json', 'r') as outfile:\n",
    "  product_info = pd.read_json(json.load(outfile), orient=\"records\")\n",
    "print(product_info.shape)\n",
    "# product_info[\"imageURLHighRes\"] = product_info[\"file_name\"].apply(lambda file_name : IMAGE_PATH/file_name)\n",
    "\n",
    "import re\n",
    "def get_space_len(s):\n",
    "  return len(max(re.findall(' +', s), key=len, default=[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/vaild_dataset.json', 'r') as outfile:\n",
    "  product_info = pd.read_json(json.load(outfile), orient=\"records\")\n",
    "  \n",
    "product_info = product_info[product_info.valid == True]\n",
    "product_info = product_info[product_info[\"perCategory\"].isin([\"AMAZON_FASHION\", 'All_Beauty',\n",
    "                                                               'Toys_and_Games','Office_Products',\n",
    "                                                              'Home_and_Kitchen','Electronics',\n",
    "                                                              'Clothing_Shoes_and_Jewelry'])]\n",
    "product_info[\"file_name\"] = product_info[\"imageURLHighRes\"].str.split(\"/\").str[-1]\n",
    "\n",
    "product_info = product_info.explode(\"description\")\n",
    "product_info['description'] = product_info['description'].str.replace(r'<[^<>]*>', '', regex=True)\n",
    "product_info[\"description\"] = product_info[\"description\"].str.split(r'\\;|\\!|\\?|\\.|\\-')\n",
    "product_info = product_info.explode(\"description\")\n",
    "product_info[\"description\"] = product_info[\"description\"].str.split(r'\\n')\n",
    "product_info = product_info.explode(\"description\")\n",
    "product_info[\"description\"] = product_info[\"description\"].str.lstrip(r'\\,')\n",
    "# product_info[\"description\"] = product_info[\"description\"].str.split(r'<br>|</td>')\n",
    "# product_info = product_info.explode(\"description\")\n",
    "\n",
    "product_info = product_info.where(\n",
    "    (product_info[\"description\"].str.len()>50) & \n",
    "    (product_info[\"description\"].astype(str).apply(get_space_len)<4) & \n",
    "    (product_info[\"description\"] != \"\") &\n",
    "    (not \"<td\" in product_info[\"description\"])\n",
    "    ).dropna().reset_index(drop=True)\n",
    "product_info[\"description\"] = product_info[\"description\"].str.strip()\n",
    "product_info['sentence_index'] = product_info.groupby('file_name').cumcount()  # Enumerate Groups\n",
    "product_info = product_info[product_info['sentence_index'] <= product_info[\"description\"].str.len().min()].reset_index(drop=True)\n",
    "print(product_info.shape)\n",
    "product_info.head(5)\n",
    "\n",
    "# for descript in product_info.loc[:10,\"description\"]:\n",
    "#     print(\"=\"*100)\n",
    "#     print(descript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "idex = random.randint(0, product_info.shape[0])\n",
    "# img_url = product_info.loc[idex,\"imageURLHighRes\"]\n",
    "img_loc = product_info.loc[idex,\"imageURLHighRes\"]\n",
    "caption = product_info.loc[idex,\"description\"]\n",
    "Category = product_info.loc[idex,[\"perCategory\", \"sentence_index\"]]\n",
    "print(caption)\n",
    "print(Category)\n",
    "print(img_loc)\n",
    "I = io.imread(img_loc)\n",
    "plt.axis('off')\n",
    "plt.imshow(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.utils.data as data\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "nltk.download('punkt')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from src.utils.data_loader import get_loader\n",
    "from src.models.CNN_Encoder import EncoderCNN\n",
    "from src.models.RNN_decoder_catAttention import DecoderRNN\n",
    "from src.models.MLP_Encoder import MlpEncoder\n",
    "from src.models.trainer import train\n",
    "from src.models.validator import validate\n",
    "from src.utils.utils_trainer import get_batch_caps, get_hypothesis, adjust_learning_rate\n",
    "from torchvision import transforms\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = \"2022-04-03-20-32-35\"\n",
    "encoder_file = 'encoder-0.pkl' \n",
    "decoder_file = 'decoder-0.pkl'\n",
    "\n",
    "log_train = f'./logs/{current_time}/training_log.txt'       # name of files with saved training loss and perplexity\n",
    "log_val = f'./logs/{current_time}/validation_log.txt'\n",
    "bleu = f'./logs/{current_time}/bleu.txt'\n",
    "vocab_file = f'./assets/{current_time}/vocab.pkl' \n",
    "\n",
    "with open(bleu, 'r') as f: \n",
    "    records = f.readlines()\n",
    "bleu_scores = []\n",
    "for record in records:\n",
    "    bleus = []\n",
    "    for blue in record.split(',')[-4:]:\n",
    "        bleus.append(float(blue.split(\":\")[-1].strip()))\n",
    "    bleu_scores.append(bleus)\n",
    "\n",
    "with open(f'../models_new/{current_time}/onehot_cat_encoder', \"rb\") as f:\n",
    "    onehot_cat_encoder = pickle.load(f)\n",
    "\n",
    "with open(f'../models_new/{current_time}/onehot_seq_encoder', \"rb\") as f:\n",
    "    onehot_seq_encoder = pickle.load(f)\n",
    "\n",
    "# Open the training log file.\n",
    "file_train = open(log_train, 'a')\n",
    "file_val = open(log_val, 'a')\n",
    "bleu_score_file = open(bleu, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_test_df = train_test_split(product_info, test_size=0.4)\n",
    "train_df.reset_index(drop=True,inplace=True)\n",
    "valid_df, test_df = train_test_split(val_test_df, test_size=0.5)\n",
    "valid_df.reset_index(drop=True,inplace=True)\n",
    "test_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "transform_test = transforms.Compose([ \n",
    "    transforms.Resize(500),                          # smaller edge of image resized to 256\n",
    "    transforms.Resize((320,320)),                      # get 224x224 crop from random location\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "])\n",
    "\n",
    "test_data_loader = get_loader(test_df,\n",
    "                        transform=transform_test,\n",
    "                        onehot_cat_encoder=onehot_cat_encoder,\n",
    "                        mode='test',\n",
    "                        onehot_seq_encoder=onehot_seq_encoder,\n",
    "                        image_type=\"imageURLHighRes\",\n",
    "                        caption_type=\"description\",\n",
    "                        vocab_file = vocab_file,\n",
    "                        batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 125           # dimensionality of image and word embeddings\n",
    "hidden_size = 512          # number of features in hidden state of the RNN decoder\n",
    "num_features = 2048        # number of feature maps, produced by Encoder\n",
    "vocab_size = len(test_data_loader.dataset.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the encoder and decoder, and set each to inference mode.\n",
    "encoder = EncoderCNN()\n",
    "encoder.eval()\n",
    "decoder = DecoderRNN(num_features = num_features, \n",
    "                     embedding_dim = embed_size,\n",
    "                     category_dim = len(onehot_cat_encoder.get_feature_names()) + len(onehot_seq_encoder.get_feature_names()),\n",
    "                     hidden_dim = hidden_size, \n",
    "                     vocab_size = vocab_size,\n",
    "                     cat_attention=True)\n",
    "decoder.eval()\n",
    "\n",
    "# Load the trained weights.\n",
    "encoder.load_state_dict(torch.load(os.path.join(f'../models_new/{current_time}', encoder_file), map_location='cpu'))\n",
    "decoder.load_state_dict(torch.load(os.path.join(f'../models_new/{current_time}', decoder_file), map_location='cpu'))\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "# Move models to GPU if CUDA is available.\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(output, data_loader):\n",
    "    vocab = data_loader.dataset.vocab.idx2word\n",
    "    words = [vocab.get(idx) for idx in output]\n",
    "    words = [word for word in words if word not in (',', '.', '<end>')]\n",
    "    sentence = \" \".join(words)\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "def get_prediction(data_loader, df):\n",
    "    print(\"=\"*20)\n",
    "    orig_image, image, cat_onehot, seq_onehot, caption= next(iter(data_loader))\n",
    "    plt.imshow(orig_image.squeeze())\n",
    "    plt.title(caption)\n",
    "    plt.show()\n",
    "    file_name = df[df[\"description\"] == caption[0]][\"file_name\"].values[0]\n",
    "    image = image.to(device)\n",
    "    #display(test_df[(test_df[\"file_name\"]==file_name)])\n",
    "    for sentence_id in range(6):\n",
    "        seq_onehot = torch.Tensor(data_loader.dataset.onehot_seq_encoder.transform(np.array([sentence_id], \n",
    "                                                                            dtype=object).reshape(-1, 1)).toarray()).long()\n",
    "        seq_onehot.to(device)\n",
    "        print(sentence_id)\n",
    "        onehot = torch.cat((cat_onehot.view(1,-1), \n",
    "                            seq_onehot.view(1,-1)), 1).type('torch.FloatTensor').view(1,-1).to(device)\n",
    "        \n",
    "        features = encoder(image)\n",
    "        output, atten_weights = decoder.greedy_search(features, onehot)    \n",
    "        sentence = clean_sentence(output,data_loader)\n",
    "        print(df[(df[\"file_name\"]==file_name) & (df[\"sentence_index\"]==sentence_id)][\"description\"].values)\n",
    "        print(sentence)\n",
    "        #print(sentence.replace(\"<unk>\", \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "for i in range(1):\n",
    "    get_prediction(test_data_loader, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "188299b107256fe873ab79b6089594fb9be85d55d578db9419dca9181f4278ba"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('deeplearn_course')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
