{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19491,"status":"ok","timestamp":1648783196784,"user":{"displayName":"Ma Yuan","userId":"07887771367764948388"},"user_tz":-480},"id":"Bpy_eeoXVOYN","outputId":"79906a22-e445-4586-93be-315f9a9c15fd"},"outputs":[],"source":["# \"\"\" Mount Google Drive to Google Colab Notebook\n","# \"\"\" \n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","# \"\"\" Change present working directory\n","# \"\"\"\n","# %cd /content/drive/MyDrive/CS5260/Github/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":509,"status":"ok","timestamp":1648783197291,"user":{"displayName":"Ma Yuan","userId":"07887771367764948388"},"user_tz":-480},"id":"aWC_C25NVpoQ","outputId":"82f91fb2-ccf8-483f-f700-ccaf5c262b4e"},"outputs":[],"source":["# %cd CS5260\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11069,"status":"ok","timestamp":1648783208359,"user":{"displayName":"Ma Yuan","userId":"07887771367764948388"},"user_tz":-480},"id":"dopRcy9uVrJk","outputId":"48d1de6a-a467-47df-faf8-10ec8dd7948d"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import skimage.io as io\n","import matplotlib.pyplot as plt\n","import torch.utils.data as data\n","import torch\n","import json\n","import os\n","import nltk\n","import random\n","from tqdm import tqdm\n","tqdm.pandas()\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1456,"status":"ok","timestamp":1648783209811,"user":{"displayName":"Ma Yuan","userId":"07887771367764948388"},"user_tz":-480},"id":"53x4XFyJsh50"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload\n","from src.utils.data_loader import get_loader"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":223},"executionInfo":{"elapsed":359,"status":"ok","timestamp":1648783210169,"user":{"displayName":"Ma Yuan","userId":"07887771367764948388"},"user_tz":-480},"id":"YiUKbENkV1Wu","outputId":"41ae1ef7-a24a-48cf-8a47-be61e7535c8d"},"outputs":[],"source":["with open('./data/vaild_dataset.json', 'r') as outfile:\n","  product_info = pd.read_json(json.load(outfile), orient=\"records\")\n","print(product_info.shape)\n","product_info.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1648783210170,"user":{"displayName":"Ma Yuan","userId":"07887771367764948388"},"user_tz":-480},"id":"pMygHtuZV9O2","outputId":"3afe04da-f2b7-4480-903b-c1ecbc86df4a"},"outputs":[],"source":["product_info[\"perCategory\"].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":354},"executionInfo":{"elapsed":340,"status":"ok","timestamp":1648783864090,"user":{"displayName":"Ma Yuan","userId":"07887771367764948388"},"user_tz":-480},"id":"ReMKWOZJ0wnE","outputId":"57c8c910-940d-481b-be0a-020291d3612e"},"outputs":[],"source":["with open('./data/vaild_dataset.json', 'r') as outfile:\n","  product_info = pd.read_json(json.load(outfile), orient=\"records\")\n","\n","import re\n","def get_space_len(s):\n","  return len(max(re.findall(' +', s), key=len, default=[0]))\n","\n","\n","product_info = product_info[product_info.valid == True]\n","product_info = product_info[product_info[\"perCategory\"].isin([\"AMAZON_FASHION\", 'All_Beauty',\n","                                                               'Toys_and_Games','Office_Products',\n","                                                              'Home_and_Kitchen','Electronics',\n","                                                              'Clothing_Shoes_and_Jewelry'])]\n","product_info[\"file_name\"] = product_info[\"imageURLHighRes\"].str.split(\"/\").str[-1]\n","\n","product_info = product_info.explode(\"description\")\n","product_info['description'] = product_info['description'].str.replace(r'<[^<>]*>', '', regex=True)\n","product_info[\"description\"] = product_info[\"description\"].str.split(r'\\;|\\!|\\?|\\.|\\-')\n","product_info = product_info.explode(\"description\")\n","product_info[\"description\"] = product_info[\"description\"].str.split(r'\\n')\n","product_info = product_info.explode(\"description\")\n","product_info[\"description\"] = product_info[\"description\"].str.lstrip(r'\\,')\n","# product_info[\"description\"] = product_info[\"description\"].str.split(r'<br>|</td>')\n","# product_info = product_info.explode(\"description\")\n","\n","product_info = product_info.where(\n","    (product_info[\"description\"].str.len()>50) & \n","    (product_info[\"description\"].astype(str).apply(get_space_len)<4) & \n","    (product_info[\"description\"] != \"\") &\n","    (not \"<td\" in product_info[\"description\"])\n","    ).dropna().reset_index(drop=True)\n","product_info[\"description\"] = product_info[\"description\"].str.strip()\n","product_info['sentence_index'] = product_info.groupby('file_name').cumcount()  # Enumerate Groups\n","product_info = product_info[product_info['sentence_index'] <= product_info[\"description\"].str.len().min()].reset_index(drop=True)\n","print(product_info.shape)\n","product_info.head(5)\n","\n","# for descript in product_info.loc[:10,\"description\"]:\n","#     print(\"=\"*100)\n","#     print(descript)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":274},"executionInfo":{"elapsed":902,"status":"ok","timestamp":1648783868843,"user":{"displayName":"Ma Yuan","userId":"07887771367764948388"},"user_tz":-480},"id":"ZCb7qEoaV_N5","outputId":"3b75e6c9-74f7-481b-f8b0-77ae7613a214"},"outputs":[],"source":["idex = random.randint(0, product_info.shape[0])\n","img_url = product_info.loc[idex,\"imageURLHighRes\"]\n","caption = product_info.loc[idex,\"description\"]\n","Category = product_info.loc[idex,\"perCategory\"]\n","print(caption)\n","print(img_url)\n","print(Category)\n","I = io.imread(img_url)\n","plt.axis('off')\n","plt.imshow(I)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"CfFzanMoZ0TF"},"source":["# Training Setup "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":289,"status":"ok","timestamp":1648783882777,"user":{"displayName":"Ma Yuan","userId":"07887771367764948388"},"user_tz":-480},"id":"amKH_lyVZtwf","outputId":"e79a7a68-f084-4ca4-ebd7-b1fc9fc84e6a"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torchvision import transforms\n","import numpy as np\n","import sys\n","import os\n","import math\n","import pickle\n","from sklearn.model_selection import train_test_split\n","import torch.utils.data as data\n","import nltk\n","from nltk.translate.bleu_score import corpus_bleu\n","nltk.download('punkt')\n","\n","%load_ext autoreload\n","%autoreload\n","from src.utils.data_loader import get_loader\n","from src.models.CNN_Encoder import EncoderCNN\n","from src.models.RNN_decoder_catAttention import DecoderRNN\n","from src.models.MLP_Encoder import MlpEncoder\n","from src.models.trainer import train\n","from src.models.validator import validate\n","from src.utils.utils_trainer import get_batch_caps, get_hypothesis, adjust_learning_rate\n","from torchvision import transforms\n","from sklearn.preprocessing import OneHotEncoder\n"]},{"cell_type":"markdown","metadata":{"id":"t8K2VoUxdaaM"},"source":["# Training Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["use_exisiting_model  = False\n","\n","if use_exisiting_model:\n","    current_time = \"2022-04-02-02-25-40\"\n","    encoder_file = 'encoder-49.pkl' \n","    decoder_file = 'decoder-49.pkl'"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1648783885282,"user":{"displayName":"Ma Yuan","userId":"07887771367764948388"},"user_tz":-480},"id":"1rPrzyGjdYGU"},"outputs":[],"source":["from datetime import datetime\n","\n","if use_exisiting_model:\n","    log_train = f'./logs/{current_time}/training_log.txt'       # name of files with saved training loss and perplexity\n","    log_val = f'./logs/{current_time}/validation_log.txt'\n","    bleu = f'./logs/{current_time}/bleu.txt'\n","    vocab_file = f'./assets/{current_time}/vocab.pkl' \n","\n","    with open(bleu, 'r') as f: \n","        records = f.readlines()\n","    bleu_scores = []\n","    for record in records:\n","        bleus = []\n","        for blue in record.split(',')[-4:]:\n","            bleus.append(float(blue.split(\":\")[-1].strip()))\n","        bleu_scores.append(bleus)\n","\n","    with open(f'../models_new/{current_time}/onehot_cat_encoder', \"rb\") as f:\n","        onehot_cat_encoder = pickle.load(f)\n","    \n","    with open(f'../models_new/{current_time}/onehot_seq_encoder', \"rb\") as f:\n","        onehot_seq_encoder = pickle.load(f)\n","\n","    # Open the training log file.\n","    file_train = open(log_train, 'a')\n","    file_val = open(log_val, 'a')\n","    bleu_score_file = open(bleu, 'a')\n","    start_epoch = int(encoder_file.split('.')[0].split('-')[-1])+1\n","    print(start_epoch)\n","    \n","else:\n","    now = datetime.now()\n","    current_time = now.strftime(\"%Y-%m-%d-%H-%M-%S\")\n","    if not os.path.exists(f'../models_new/{current_time}'):\n","        os.makedirs(f'../models_new/{current_time}')\n","    if not os.path.exists(f'./logs/{current_time}'):\n","        os.makedirs(f'./logs/{current_time}')\n","    if not os.path.exists(f'./assets/{current_time}'):\n","        os.makedirs(f'./assets/{current_time}')\n","    \n","    vocab_file = f'./assets/{current_time}/vocab.pkl' \n","    log_train = f'./logs/{current_time}/training_log.txt'       # name of files with saved training loss and perplexity\n","    log_val = f'./logs/{current_time}/validation_log.txt'\n","    bleu = f'./logs/{current_time}/bleu.txt'\n","    \n","    # Open the training log file.\n","    file_train = open(log_train, 'w')\n","    file_val = open(log_val, 'w')\n","    bleu_score_file = open(bleu, 'w')\n","\n","    start_epoch= 0 \n","    bleu_scores = []\n","\n","    image_dict = product_info[\"imageURLHighRes\"].to_dict()\n","    caption_dict = product_info[\"description\"].to_dict()\n","    category_dict = product_info[\"perCategory\"].to_dict()\n","    sentence_id_dict = product_info[\"sentence_index\"].to_dict()\n","\n","    onehot_cat_encoder = OneHotEncoder(handle_unknown='ignore').fit(np.array([*category_dict.values()], dtype=object).reshape(-1, 1))\n","    with open(f'../models_new/{current_time}/onehot_cat_encoder', \"wb\") as f: \n","        pickle.dump(onehot_cat_encoder, f)\n","    \n","    onehot_seq_encoder = OneHotEncoder(handle_unknown='ignore').fit(np.array([*sentence_id_dict.values()], dtype=object).reshape(-1, 1))\n","    with open(f'../models_new/{current_time}/onehot_seq_encoder', \"wb\") as f: \n","        pickle.dump(onehot_seq_encoder, f)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["batch_size = 10          # batch size, change to 64\n","vocab_threshold = 5        # minimum word count threshold\n","vocab_from_file = False    # if True, load existing vocab file\n","embed_size = 125           # dimensionality of image and word embeddings\n","hidden_size = 512          # number of features in hidden state of the RNN decoder\n","num_features = 2048        # number of feature maps, produced by Encoder\n","num_epochs = 200               # number of training epochs\n","save_every = 1             # determines frequency of saving model weights\n","print_every = 100          # determines window for printing average loss"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1810,"status":"ok","timestamp":1648783890915,"user":{"displayName":"Ma Yuan","userId":"07887771367764948388"},"user_tz":-480},"id":"AAy3gNw9Z8B-","outputId":"3fd43465-1a24-48cc-b374-5078b1952a2c"},"outputs":[],"source":["train_df, val_test_df = train_test_split(product_info, test_size=0.4)\n","train_df.reset_index(drop=True,inplace=True)\n","valid_df, test_df = train_test_split(val_test_df, test_size=0.5)\n","valid_df.reset_index(drop=True,inplace=True)\n","test_df.reset_index(drop=True,inplace=True)\n","\n","# transform_train = transforms.Compose([ \n","#     transforms.Resize(500),                          # smaller edge of image resized to 256\n","#     transforms.Resize((320,320)),                      # get 224x224 crop from random location\n","#     transforms.ToTensor(),                           # convert the PIL Image to a tensor\n","#     transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n","#                          (0.229, 0.224, 0.225))])\n","transform_train = transforms.Compose([ \n","    transforms.Resize(500),                          # smaller edge of image resized to 256\n","    transforms.Resize((320,320)),                      # get 224x224 crop from random location\n","    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n","])\n","\n","\n","# Build data loader.\n","data_loader = get_loader(train_df,\n","                        transform=transform_train,\n","                        onehot_cat_encoder=onehot_cat_encoder,\n","                        mode='train',\n","                        onehot_seq_encoder=onehot_seq_encoder,\n","                        image_type=\"imageURLHighRes\",\n","                        caption_type=\"description\",\n","                        vocab_file = vocab_file,\n","                        batch_size=batch_size,\n","                        vocab_threshold=vocab_threshold,\n","                        vocab_from_file=use_exisiting_model)\n","\n","\n","# The size of the vocabulary.\n","vocab_size = len(data_loader.dataset.vocab)\n","print(vocab_size)\n","\n","print('The shape of first image:', data_loader.dataset[0][0].shape)\n","print('Total number of tokens in vocabulary:', len(data_loader.dataset.vocab))\n","\n","# Randomly sample a caption length, and sample indices with that length.\n","indices = data_loader.dataset.get_indices()\n","print('sampled indices:', indices)\n","\n","# Create and assign a batch sampler to retrieve a batch with the sampled indices.\n","new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n","data_loader.batch_sampler.sampler = new_sampler\n","    \n","# Obtain the batch.\n","images, onehot_cat, onehot_enc_seq, captions = next(iter(data_loader))\n","    \n","print('images.shape:', images.shape)\n","print('onehot_cat.shape:', onehot_cat.shape)\n","print('captions.shape:', captions.shape)\n","\n","plt.axis('off')\n","plt.imshow(images[0].detach().T)\n","plt.show()\n","\n","# Setup the transforms\n","transform_test = transforms.Compose([ \n","    transforms.Resize(500),                          # smaller edge of image resized to 256\n","    transforms.Resize((320,320)),                      # get 224x224 crop from random location\n","    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n","])\n","\n","# Create the data loader.\n","valid_data_loader = get_loader(valid_df,\n","                        transform=transform_train,\n","                        onehot_cat_encoder=onehot_cat_encoder,\n","                        mode='valid',\n","                        onehot_seq_encoder=onehot_seq_encoder,\n","                        image_type=\"imageURLHighRes\",\n","                        caption_type=\"description\",\n","                        vocab_file = vocab_file,\n","                        batch_size=batch_size)\n","\n","\n","total_step_valid = math.ceil(len(valid_data_loader.dataset.caption_lengths) / valid_data_loader.batch_sampler.batch_size)\n","total_step_valid"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["encoder = EncoderCNN()\n","decoder = DecoderRNN(num_features = num_features, \n","                    embedding_dim = embed_size, \n","                    category_dim = len(set(category_dict.values())) + len(set(sentence_id_dict.values())) ,\n","                    hidden_dim = hidden_size, \n","                    vocab_size = vocab_size,\n","                    cat_attention = True)\n","\n","\n","if use_exisiting_model:\n","    encoder.load_state_dict(torch.load(os.path.join(f'../models_new/{current_time}', encoder_file), map_location='cpu'))\n","    decoder.load_state_dict(torch.load(os.path.join(f'../models_new/{current_time}', decoder_file), map_location='cpu'))\n","\n","\n","\n","# Move models to GPU if CUDA is available. \n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","encoder.to(device)\n","decoder.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1648783893855,"user":{"displayName":"Ma Yuan","userId":"07887771367764948388"},"user_tz":-480},"id":"CiCEogngffwY","outputId":"3b33f542-965e-455c-a859-4e7b63fa205b"},"outputs":[],"source":["print(device)\n","# Define the loss function. \n","criterion = nn.CrossEntropyLoss()\n","criterion.to(device)\n","#params = list(decoder.parameters()) + list(encoder.parameters()) \n","params = list(decoder.parameters())\n","\n","# TODO #4: Define the optimizer.\n","grad_clip = 5.  # clip gradients at an absolute value of\n","alpha_c = 1.  # regularization parameter for 'doubly stochastic attention', as in the paper\n","\n","encoder_lr = 1e-3  # learning rate for encoder if fine-tuning\n","encoder_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, encoder.parameters()),lr=encoder_lr)\n","encoder_lr_scheduler = torch.optim.lr_scheduler.CyclicLR(encoder_optimizer, \n","                                                         base_lr=encoder_lr/10, max_lr=encoder_lr*10, \n","                                                         step_size_up = 10 , step_size_down=20, cycle_momentum=False)\n","\n","\n","decoder_lr = 1e-3  # learning rate for decoder\n","decoder_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, decoder.parameters()),lr=decoder_lr)\n","decoder_lr_scheduler = torch.optim.lr_scheduler.CyclicLR(decoder_optimizer, \n","                                                         base_lr=decoder_lr/10, max_lr=decoder_lr*10, \n","                                                         step_size_up = 10 , step_size_down=20, cycle_momentum=False)\n","\n","fine_tune_encoder = False  # fine-tune encoder?\n","checkpoint = None  # path to checkpoint, None if none\n","\n","# Set the total number of training steps per epoch.\n","total_step = math.ceil(len(data_loader.dataset.caption_lengths) / data_loader.batch_sampler.batch_size)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R0ygLO8gdljX","outputId":"86fb3391-5c79-4571-8982-c8859f0cda55"},"outputs":[],"source":["\n","# store BLEU scores in list \n","\n","total_step_valid = math.ceil(len(valid_data_loader.dataset.caption_lengths) / valid_data_loader.batch_sampler.batch_size)\n","epochs_since_improvement = 0\n","best_bleu = 0.\n","\n","for epoch in range(start_epoch, num_epochs+1):\n","    # Decay learning rate if there is no improvement for 8 consecutive epochs, and terminate training after 20\n","    if epochs_since_improvement == 50:\n","        break\n","    if epochs_since_improvement > 0 and epochs_since_improvement % 20 == 0:\n","        adjust_learning_rate(decoder_optimizer, 0.8)\n","        if fine_tune_encoder:\n","            adjust_learning_rate(encoder_optimizer, 0.8)\n","\n","    train(epoch, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, total_step, num_epochs =num_epochs,\n","          data_loader = data_loader,\n","          write_file = file_train, \n","          vocab_size = vocab_size,\n","          batch_size = batch_size,\n","          device = device,\n","          print_every = print_every,\n","          save_every = 1)\n","    \n","    bleus= validate(epoch, encoder, decoder, \n","                    encoder_optimizer, decoder_optimizer, criterion, \n","                    vocab_size = vocab_size,\n","                    batch_size = batch_size,\n","                    device = device,\n","                    print_every = print_every,\n","                    total_step = total_step_valid, \n","                    num_epochs = num_epochs, \n","                    data_loader = valid_data_loader, \n","                    write_file=file_val, \n","                    bleu_score_file=bleu_score_file)\n","    \n","    bleu_scores.append(bleus)\n","    # encoder_lr_scheduler.step()\n","    # decoder_lr_scheduler.step()\n","    \n","    # Check if there was an improvement\n","    is_best = sum(bleus)/4 > best_bleu\n","    best_bleu = max(sum(bleus)/4, best_bleu)\n","    if not is_best:\n","        epochs_since_improvement += 1\n","        print(\"\\nEpochs since last improvement: %d\\n\" % (epochs_since_improvement,))\n","    else:\n","        torch.save(decoder.state_dict(), os.path.join(f'../models_new/{current_time}', 'decoder-%d.pkl' % epoch))\n","        torch.save(encoder.state_dict(), os.path.join(f'../models_new/{current_time}', 'encoder-%d.pkl' % epoch))\n","        epochs_since_improvement = 0\n","    \n","file_train.close()\n","file_val.close()\n","bleu_score_file.close()"]},{"cell_type":"markdown","metadata":{"id":"EXZjXmeKkVpF"},"source":["# Generate Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1648783226919,"user":{"displayName":"Ma Yuan","userId":"07887771367764948388"},"user_tz":-480},"id":"eoKMDZj9fSHB"},"outputs":[],"source":["# Setup the transforms\n","# transform_test = transforms.Compose([ \n","#     transforms.Resize((320,320)),                          # smaller edge of image resized to 256\n","#     transforms.ToTensor(),                           # convert the PIL Image to a tensor\n","#     transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n","#                          (0.229, 0.224, 0.225))])\n","\n","transform_test = transforms.Compose([ \n","    transforms.Resize(500),                          # smaller edge of image resized to 256\n","    transforms.Resize((320,320)),                      # get 224x224 crop from random location\n","    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1648783226920,"user":{"displayName":"Ma Yuan","userId":"07887771367764948388"},"user_tz":-480},"id":"r2OmJZeAkZOA","outputId":"5f64ee9e-32ad-4ec6-90a2-660f18d274f7"},"outputs":[],"source":["test_data_loader = get_loader(test_df,\n","                              image_type=\"imageURLHighRes\",\n","                              caption_type=\"description\",\n","                              transform=transform_test,\n","                              onehot_cat_encoder=onehot_cat_encoder,\n","                              onehot_seq_encoder=onehot_seq_encoder,\n","                              batch_size=1,\n","                              mode='test')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2162,"status":"ok","timestamp":1648783480190,"user":{"displayName":"Ma Yuan","userId":"07887771367764948388"},"user_tz":-480},"id":"gG0n30hxkZ1p","outputId":"4ca52eba-f618-4b93-b555-408ec974c7ba"},"outputs":[],"source":["encoder_file = 'encoder-0.pkl' \n","decoder_file = 'decoder-0.pkl'\n","\n","embed_size = 125           # dimensionality of image and word embeddings\n","hidden_size = 512          # number of features in hidden state of the RNN decoder\n","num_features = 2048        # number of feature maps, produced by Encoder\n","\n","# The size of the vocabulary.\n","vocab_size = 3633#len(test_data_loader.dataset.vocab)\n","\n","# Initialize the encoder and decoder, and set each to inference mode.\n","encoder = EncoderCNN()\n","encoder.eval()\n","decoder = DecoderRNN(num_features = num_features, \n","                     embedding_dim = embed_size,\n","                     category_dim = len(set(category_dict.values())) + len(set(sentence_id_dict.values())),\n","                     hidden_dim = hidden_size, \n","                     vocab_size = vocab_size)\n","decoder.eval()\n","\n","current_time = \"2022-03-31-16-43-01\"\n","# Load the trained weights.\n","encoder.load_state_dict(torch.load(os.path.join(f'../models_new/{current_time}', encoder_file), map_location='cpu'))\n","decoder.load_state_dict(torch.load(os.path.join(f'../models_new/{current_time}', decoder_file), map_location='cpu'))\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Move models to GPU if CUDA is available.\n","encoder.to(device)\n","decoder.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1648783779953,"user":{"displayName":"Ma Yuan","userId":"07887771367764948388"},"user_tz":-480},"id":"V0KU8OfClOIW"},"outputs":[],"source":["def clean_sentence(output, data_loader):\n","    vocab = data_loader.dataset.vocab.idx2word\n","    words = [vocab.get(idx) for idx in output]\n","    words = [word for word in words if word not in (',', '.', '<end>')]\n","    sentence = \" \".join(words)\n","    \n","    return sentence\n","\n","def get_prediction(data_loader):\n","    orig_image, image, cat_onehot, seq_onehot, caption= next(iter(data_loader))\n","    plt.imshow(orig_image.squeeze())\n","    print(cat_onehot.size())\n","    plt.title(caption)\n","    plt.show()\n","    image = image.to(device)\n","    onehot = torch.cat((cat_onehot.view(1,-1), \n","                            seq_onehot.view(1,-1)), 1).type('torch.FloatTensor').view(1,-1).to(device)\n","    \n","    features = encoder(image)\n","    output, atten_weights = decoder.greedy_search(features, onehot)    \n","    sentence = clean_sentence(output,data_loader)\n","    print(sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":316},"executionInfo":{"elapsed":1676,"status":"ok","timestamp":1648783799998,"user":{"displayName":"Ma Yuan","userId":"07887771367764948388"},"user_tz":-480},"id":"Yp_rp5M2lLWR","outputId":"1407852a-bb4c-4af6-ac71-01aff83b7d2f"},"outputs":[],"source":["get_prediction(test_data_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1y3w5XZ2lPLW"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPYOOfPH6GRnxltdA0RDJZ1","collapsed_sections":[],"name":" CS5260Project_new.ipynb","provenance":[{"file_id":"1YM0Jy9EduI_QyNiWzVfvTofHNsteVu81","timestamp":1648551625627}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat":4,"nbformat_minor":0}
